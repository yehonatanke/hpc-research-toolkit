
===== ARGUMENTS =====


	-log_filepath: /leonardo_work/AIFAC_S02_060/data/yk/code/viser/dl3dv/logs/log_4.txt

	-debug: 1

	-dataset_root: /leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba

	-port: 8080

	-host: 0.0.0.0

	-frame_skip: 1

	-downsample: 4

	-default_depth_scale: 1.0

	-default_max_depth: 100.0

===== END OF ARGUMENTS =====

[DEBUG] [main() @ render_scene.py:377] DEBUG_LEVEL: [1].
[DEBUG] [main() @ render_scene.py:384] Loading scene metadata from: [/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/scene_meta.json]
[DEBUG] [load_scene_meta() @ render_scene.py:327] Loading scene metadata from: [dataset_root=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/scene_meta.json]
[DEBUG] [main() @ render_scene.py:400] Found [332] frames. Processing every [1] frame(s).
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00001.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00002.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00003.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00004.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00005.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00006.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00007.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00008.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00009.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00010.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00011.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00012.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00013.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00014.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00015.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00016.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00017.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00018.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00019.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00020.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00021.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00022.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00023.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00024.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00025.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00026.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00027.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00028.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00029.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00030.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00031.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00032.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00033.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00034.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00035.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00036.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00037.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00038.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00039.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00040.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00041.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00042.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00043.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00044.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00045.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00046.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00047.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00048.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00049.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00050.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00051.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00052.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00053.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00054.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00055.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00056.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00057.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00058.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00059.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00060.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00061.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00062.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00063.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00064.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00065.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00066.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00067.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00068.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00069.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00070.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00071.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00072.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00073.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00074.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00075.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00076.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00077.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00078.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00079.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00080.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00081.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00082.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00083.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00084.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00085.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00086.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00087.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00088.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00089.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00090.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00091.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00092.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00093.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00094.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00095.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00096.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00097.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00098.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00099.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00100.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00101.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00102.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00103.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00104.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00105.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00106.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00107.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00108.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00109.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00110.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00111.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00112.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00113.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00114.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00115.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00116.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00117.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00118.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00119.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00120.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00121.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00122.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00123.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00124.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00125.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00126.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00127.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00128.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00129.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00130.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00131.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00132.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00133.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00134.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00135.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00136.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00137.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00138.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00139.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00140.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00141.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00142.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00143.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00144.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00145.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00146.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00147.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00148.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00149.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00150.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00151.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00152.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00153.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00154.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00155.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00156.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00157.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00158.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00159.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00160.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00161.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00162.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00163.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00164.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00165.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00166.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00167.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00168.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00169.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00170.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00171.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00172.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00173.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00174.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00175.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00176.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00177.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00178.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00179.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00180.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00181.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00182.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00183.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00184.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00185.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00186.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00187.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00188.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00189.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00190.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00191.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00192.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00193.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00194.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00195.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00196.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00197.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00198.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00199.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00200.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00201.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00202.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00203.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00204.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00205.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00206.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00207.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00208.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00209.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00210.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00211.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00212.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00213.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00214.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00215.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00216.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00217.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00218.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00219.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00220.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00221.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00222.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00223.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00224.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00225.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00226.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00227.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00228.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00229.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00230.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00231.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00232.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00233.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00234.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00235.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00236.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00237.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00238.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00239.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00240.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00241.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00242.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00243.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00244.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00245.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00246.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00247.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00248.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00249.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00250.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00251.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00252.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00253.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00254.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00255.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00256.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00257.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00258.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00259.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00260.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00261.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00262.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00263.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00264.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00265.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00266.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00267.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00268.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00269.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00270.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00271.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00272.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00273.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00274.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00275.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00276.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00277.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00278.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00279.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00280.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00281.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00282.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00283.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00284.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00285.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00286.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00287.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00288.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00289.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00290.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00291.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00292.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00293.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00294.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00295.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00296.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00297.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00298.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00299.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00300.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00301.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00302.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00303.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00304.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00305.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00306.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00307.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00308.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00309.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00310.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00311.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00312.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00313.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00314.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00315.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00316.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00317.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00318.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00319.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00320.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00321.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00322.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00323.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00324.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00325.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00326.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00327.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00328.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00329.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00330.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00331.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [find_depth_file() @ render_scene.py:205] Found depth file: [depth_path=/leonardo_work/AIFAC_S02_060/data/yk/debug/dl3dv_wai_dummy/1K_00b1ad87c296635c73bbc9728a63d3df4a9ab07aee0d34cd45784e39f2c699ba/mvsanywhere/v0/depth/frame_00332.exr].
[DEBUG] [load_depth_map() @ render_scene.py:123] Loaded depth map (from EXR file) with: depth.shape=[(480, 640)].
[DEBUG] [parse_transform_matrix() @ render_scene.py:338] Parsing transformation matrix with: transform.length=[4].
[DEBUG] [main() @ render_scene.py:498] Successfully processed [332] frames.
[DEBUG] [update_point_clouds() @ render_scene.py:521] Using values from sliders: depth_scale=[1.000], max_depth=[100.0], point_size=[0.010].
[DEBUG] [update_point_clouds() @ render_scene.py:528] Updating point clouds with: 
	-depth_scale=[1.000] 
	-max_depth=[100.0] 
	-point_size=[0.010].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:238] Unprojecting points with: 
	-depth.shape=[(480, 640)] 
	-rgb.shape=[(267, 479, 3)] 
	-intrinsics=[{'fl_x': 215.93148803710938, 'fl_y': 215.71319580078125, 'cx': 241.02354431152344, 'cy': 135.03375244140625}] 
	-transform_matrix.shape=[(4, 4)] 
	-depth_scale=[1.0] 
	-max_depth=[100.0] 
	-downsample=[4].
[DEBUG] [unproject_points() @ render_scene.py:247] Resized depth to match RGB dimensions with: depth.shape=[(267, 479)].
[DEBUG] [unproject_points() @ render_scene.py:261] Downsampled depth and RGB with: depth.shape=[(67, 120)] rgb.shape=[(67, 120, 3)].
[DEBUG] [unproject_points() @ render_scene.py:276] Scaling intrinsics if downsampled. scale factor: [4].
[DEBUG] [unproject_points() @ render_scene.py:277] Scaling intrinsics if downsampled with: cx=[241.02354431152344] cy=[135.03375244140625] fl_x=[215.93148803710938] fl_y=[215.71319580078125].
[DEBUG] [unproject_points() @ render_scene.py:306] Indexed RGB with the valid mask with: 
	-colors=[(8040, 3)].
[DEBUG] [unproject_points() @ render_scene.py:321] Transformed to world coordinates with: points_cam.shape=[(8040, 3)] points_world.shape=[(8040, 3)] colors.shape=[(8040, 3)].
[DEBUG] [update_point_clouds() @ render_scene.py:582] Added point cloud with [2669280] points.
[DEBUG] [add_camera_frustums() @ render_scene.py:599] Adding camera frustums.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.04506504  0.67291071  0.73832273 -0.00631298]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.04498752  0.67285764  0.73838321 -0.0053817 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.04510296  0.67286794  0.73837937 -0.00321843]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.04590328  0.67294423  0.73826226 -0.00279138]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.04826992  0.67239102  0.73861329 -0.00327809]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.05244661  0.67186791  0.7387957  -0.00487667]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.06023556  0.67134482  0.73865357 -0.00766249]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.0706495   0.67065769  0.73832463 -0.01018082]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.07957427  0.66972898  0.73823418 -0.01188824]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.09206202  0.66869075  0.73771695 -0.01228683]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.10238319  0.66770972  0.73727054 -0.01065633]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.11287724  0.66680648  0.73659753 -0.00720619]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.1208045   0.66624306  0.73588153 -0.0021969 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.12540449  0.6662246   0.73512305  0.0035503 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.12763197  0.66681967  0.73416519  0.0079418 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.12814789  0.66785406  0.73308364  0.01172409]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.12762957  0.66966446  0.73146851  0.01462978]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.12729994  0.671499    0.72981266  0.01604019]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.12698876  0.67393022  0.72761337  0.016453  ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.12682621  0.67635392  0.72538251  0.01675451]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.12757393  0.6783378   0.72339972  0.01660009]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.12930774  0.68071803  0.72082761  0.01760782]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.13077923  0.68212545  0.71919546  0.01896208]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.13373353  0.68361277  0.71718133  0.02097302]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.13709985  0.68533233  0.71481075  0.02384986]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.14056734  0.68638263  0.71303463  0.0264827 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.1448294   0.68712741  0.71135757  0.02916793]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.15062062  0.68748671  0.70963577  0.03305342]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.16030555  0.68673169  0.70790846  0.03958945]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.16823109  0.68562457  0.70684465  0.04458582]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.18022848  0.68230318  0.70658798  0.05209121]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.18657141  0.67980724  0.70706522  0.05578526]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.19375395  0.67617593  0.70833403  0.05923193]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.19931893  0.67278763  0.7098074   0.06166213]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.204312    0.66906537  0.71175248  0.06337622]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.2100914   0.66484242  0.71400117  0.06362767]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.21308328  0.66254851  0.71532346  0.06274828]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.216256    0.66008299  0.71679734  0.0610357 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.21943447  0.65824832  0.71764942  0.05947246]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.22269946  0.65624323  0.71852138  0.05896436]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.22610407  0.65393418  0.71954207  0.05921366]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.22891273  0.6517553   0.72053685  0.06033765]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.23231839  0.64924153  0.72155451  0.06223096]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.2358915   0.64671622  0.72239183  0.06529453]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.23914615  0.64475601  0.72281338  0.06811471]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.24195518  0.64323824  0.72296576  0.07087154]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.24631449  0.6414828   0.72260264  0.07532873]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.25058801  0.63983316  0.72212844  0.07968502]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.25370252  0.63852559  0.72181692  0.08306886]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.25832716  0.63628396  0.72148353  0.08872044]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.26052357  0.63433542  0.72194263  0.09243857]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.2625454   0.63210812  0.7227111   0.09590571]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.26344603  0.63044261  0.72352886  0.09820542]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.26473191  0.62765302  0.72515428  0.10059808]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.26557112  0.62579163  0.72629197  0.10176832]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.26613608  0.62452151  0.72705005  0.10267767]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.26763103  0.62330983  0.72738012  0.10381065]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.26908362  0.62243906  0.72734611  0.10550479]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.27092898  0.62155155  0.72701445  0.10826427]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.27285159  0.6207104   0.72639906  0.11231659]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.27540907  0.61960508  0.72568852  0.1166857 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.27806373  0.61823854  0.72497893  0.12193127]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.2820932   0.61623075  0.72397283  0.12863294]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.28662508  0.61403792  0.72288607  0.13505272]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.29192444  0.6113934   0.72157828  0.14248865]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.29594228  0.60933897  0.72049706  0.14835152]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.30443624  0.6047705   0.71807447  0.16105988]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.31218271  0.60085578  0.71529403  0.17282574]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.32033274  0.59707361  0.71195348  0.18442419]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.32884065  0.5928179   0.7082068   0.19716463]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.33708446  0.58876482  0.70400909  0.21000296]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.34525624  0.58480826  0.69940401  0.22278117]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.35172688  0.58122884  0.69565734  0.23349968]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.36007438  0.57530429  0.69099848  0.24878205]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.36598016  0.57033209  0.68766064  0.2605814 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.37054107  0.56570767  0.68535926  0.27010522]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.37497698  0.56051223  0.68317444  0.28016243]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.37894756  0.55614153  0.68129392  0.28799988]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.38259392  0.553023    0.67900933  0.294506  ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.38760817  0.55015062  0.6753711   0.30160915]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.39227311  0.54779728  0.67161291  0.30818183]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.39697483  0.54555021  0.66755941  0.31488155]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.40298712  0.54253882  0.66230534  0.32342642]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.40919994  0.53863423  0.6579459   0.33096188]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.41617788  0.53343864  0.65375971  0.33887674]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.42255974  0.52825994  0.65061009  0.34509595]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.43120197  0.52090057  0.64728298  0.3517843 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.43644014  0.51605945  0.64587326  0.35503575]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.44626542  0.5067329   0.64393738  0.35974101]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.4549378   0.49783766  0.64345741  0.36214891]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.46255968  0.48948531  0.64449261  0.3620386 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.46936542  0.48133468  0.64647955  0.3606622 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.47570054  0.47313047  0.64918655  0.35834813]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.48061632  0.46612723  0.65234318  0.35522069]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.48506679  0.45955581  0.65586003  0.35123538]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.48876994  0.45418824  0.65880862  0.34754596]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.49269442  0.44904881  0.66200082  0.34258181]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.49539556  0.44558605  0.66411762  0.33909306]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.49815774  0.44287127  0.66510589  0.33665718]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.50347606  0.43746499  0.66563909  0.3347549 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.50970751  0.43157751  0.6642557   0.33571337]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.51684444  0.42468942  0.66132704  0.33934829]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.5258525   0.41610057  0.65629031  0.34586484]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.5368501   0.405887    0.6485844   0.35550807]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.54830972  0.39583133  0.63892034  0.36668081]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.55824324  0.38770682  0.62929197  0.37688131]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.57133876  0.37736866  0.61480401  0.39138338]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.58188758  0.36890024  0.6024914   0.40289399]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.59273393 -0.35881887 -0.58831174 -0.41689903]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.59998717 -0.35083909 -0.57865523 -0.42671472]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.60650095 -0.34210099 -0.5697571  -0.43646347]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.61175314 -0.33458191 -0.56338832 -0.44317789]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.6162093  -0.32693062 -0.5584592  -0.44891625]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.6201817  -0.31913478 -0.55507606 -0.45323086]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.62340994 -0.31345975 -0.55291718 -0.45539611]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.6257468  -0.30890986 -0.55121727 -0.45735671]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.62750275 -0.30573708 -0.54962616 -0.4589948 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.63086776 -0.30097145 -0.54646398 -0.46130161]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.63252292 -0.29855722 -0.54318823 -0.46446193]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.63297504 -0.29787251 -0.54117703 -0.46662832]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.63280472 -0.29749646 -0.53986072 -0.46861973]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.63196385 -0.29776823 -0.53866568 -0.47095123]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.62930384 -0.29959516 -0.53889634 -0.47308578]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.62669932 -0.30133228 -0.53956059 -0.47468009]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.62517675 -0.30151696 -0.54038929 -0.47562692]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.6246699  -0.30078692 -0.540188   -0.47698183]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.62578179 -0.29851662 -0.53863719 -0.47870133]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.6280499  -0.29547819 -0.53567692 -0.48093264]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.6309509  -0.29196139 -0.53181396 -0.48356325]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.63529661 -0.28706039 -0.52432704 -0.48895368]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.6382194  -0.28336583 -0.51753033 -0.49451204]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.64102268 -0.2798526  -0.51178763 -0.49884454]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.64367204 -0.27694215 -0.50397611 -0.5049727 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.64587946 -0.27504606 -0.49776944 -0.50932796]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.64772087 -0.27372664 -0.49316375 -0.51217275]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.64988213 -0.2718729  -0.4888597  -0.51454304]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.6513695  -0.27084527 -0.48601791 -0.51589457]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.65329585 -0.26948755 -0.48404775 -0.51602206]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.65503935 -0.2678231  -0.48317007 -0.51550064]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.6570211  -0.2661614  -0.48299966 -0.51399679]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.65924751 -0.26529907 -0.48187775 -0.51264312]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.66033329 -0.26514035 -0.48107864 -0.512078  ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.66162916 -0.26563901 -0.48005231 -0.51110914]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.66276784 -0.26673907 -0.47960451 -0.50947872]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.66361074 -0.26831922 -0.47851764 -0.50857296]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.66395031 -0.2710108  -0.47711358 -0.50802141]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.66461904 -0.2722318  -0.4765482  -0.50702386]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.66539254 -0.27315219 -0.47563855 -0.50636807]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.6659657  -0.27361168 -0.47514823 -0.50582655]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.66644534 -0.27464865 -0.47536183 -0.50443023]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.66642302 -0.27459822 -0.47762163 -0.50234824]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.66561044 -0.27474684 -0.48088468 -0.50022679]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.66416222 -0.27444444 -0.48661041 -0.49676866]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.66259627 -0.27413226 -0.49079241 -0.49491464]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.6610427  -0.2730253  -0.49516657 -0.49324416]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.6595211  -0.27160801 -0.49847627 -0.49272955]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.65791251 -0.27020716 -0.5002391  -0.49386239]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.65535823 -0.26863211 -0.50127056 -0.49706158]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.65235897 -0.26787042 -0.50207186 -0.50059671]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.64864337 -0.26736524 -0.503247   -0.50449981]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.6440323  -0.26701376 -0.50531867 -0.50850672]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.63855643 -0.26776942 -0.50822891 -0.51210213]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.63292846 -0.27006008 -0.51177999 -0.5143446 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.62846784 -0.27320203 -0.51548952 -0.51445056]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.62575473 -0.27684767 -0.51891222 -0.51236364]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.62410339 -0.28473257 -0.52258524 -0.50628747]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.62453975 -0.28822367 -0.52423731 -0.50204826]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.62719659 -0.29494103 -0.52544298 -0.49350168]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.63137465 -0.30067529 -0.52559784 -0.48446604]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.63519468 -0.30770215 -0.52509283 -0.47552563]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.63788017 -0.31552996 -0.52456998 -0.46730725]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.63853465 -0.32322334 -0.5246791  -0.46099025]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.63722394 -0.33183161 -0.52660394 -0.4544466 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.63330645 -0.33925141 -0.53158026 -0.44861324]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.62773057 -0.34603021 -0.53795837 -0.443642  ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.62058361 -0.35250174 -0.54598851 -0.43876538]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.61231191 -0.35892708 -0.55549424 -0.43321084]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.60430709 -0.36507756 -0.56454626 -0.42757319]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.59654155 -0.37215153 -0.57189224 -0.42258808]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.59043354 -0.37896212 -0.57684462 -0.41836137]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[ 0.58354068 -0.38754403 -0.58234694 -0.4125069 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.57811851  0.3935667   0.58749404  0.40710563]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.57392518  0.39863926  0.59144803  0.40235041]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.57028636  0.40239542  0.59545533  0.39784965]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.56702794  0.4042786   0.599507    0.39449902]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.56328578  0.40584045  0.60477836  0.39018686]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.56018099  0.40731419  0.6086603   0.38707241]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.55648817  0.4082192   0.61389614  0.38315731]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.55148962  0.40970888  0.62048272  0.37815212]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.54676484  0.41108237  0.62683429  0.37301241]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.54343759  0.41173317  0.63254566  0.36747433]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.54009772  0.41274549  0.63766849  0.36237343]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.53692083  0.41452392  0.64199302  0.35739461]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.53442002  0.41734914  0.64420777  0.35385207]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.53300215  0.41994088  0.64504074  0.35139836]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.53111533  0.42331024  0.64508292  0.35013279]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.52992512  0.42595884  0.64442335  0.34993853]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.52969166  0.42866969  0.64244644  0.35061604]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.52959     0.42988602  0.64142076  0.35115786]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.52914711  0.43029695  0.64123343  0.35166398]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.52918997  0.43057367  0.64070535  0.35222287]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.52980861  0.42995322  0.64070675  0.3520482 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.52895254  0.43033633  0.64170734  0.3510435 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.52775811  0.43113798  0.64290877  0.34965659]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.52682615  0.43252089  0.643764    0.34777551]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.52498892  0.43491474  0.64519681  0.34490125]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.52286311  0.43756574  0.64660702  0.34212536]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.51806554  0.44439965  0.64850772  0.33697889]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.51450613  0.44891846  0.65027502  0.33301361]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.50926643  0.45436763  0.65330313  0.32770838]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.50450093  0.45966052  0.6556037   0.32307092]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.50088558  0.46354519  0.65716355  0.31996181]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.49741126  0.46642439  0.65950035  0.31636943]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.49510326  0.46810601  0.66131028  0.31371681]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.49455527  0.46874202  0.66277346  0.31052754]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.49492416  0.46821475  0.66394343  0.30822743]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.49510038  0.46751835  0.6651114   0.30647845]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.49610073  0.46602888  0.66677734  0.30349486]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.49720362  0.4651493   0.66784877  0.30067044]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.4956703   0.46579974  0.67030326  0.29670708]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.49216166  0.46765957  0.67375513  0.29176266]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.48806192  0.47088853  0.67666243  0.28668362]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.48047933  0.47597775  0.68164868  0.27917712]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.47476111  0.47937666  0.68544177  0.27380555]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.46541698  0.4851053   0.6910355   0.26557451]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.45783577  0.489733    0.69536625  0.25887017]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.44907992  0.49490997  0.70037246  0.25073844]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.44068978  0.50002423  0.70462869  0.24344752]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.42874897  0.5086336   0.70915671  0.23358713]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.41929089  0.51563499  0.71202856  0.22656354]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.40690561  0.52471137  0.71488071  0.21920625]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.39674658  0.53315372  0.71597816  0.21380957]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.38863712  0.54005288  0.71610377  0.21094896]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.3802661   0.54653585  0.71662555  0.20771153]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.36985553  0.55431646  0.71679234  0.20530194]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.36216454  0.56117452  0.71591783  0.20342486]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.35461852  0.56657424  0.71629531  0.20040049]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.34512649  0.57233552  0.71760311  0.19587123]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.33906037  0.57646891  0.71862042  0.19054227]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.33228503  0.58018546  0.72016974  0.18527558]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.32531838  0.58287678  0.72266098  0.17939822]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.31708937  0.58601259  0.72538626  0.1727957 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.31188849  0.58871917  0.72674682  0.16725543]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.30589346  0.59169984  0.72782672  0.16306061]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.29797511  0.59515143  0.72912271  0.15932886]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.29220127  0.59809748  0.72932848  0.15804365]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.28761139  0.60058697  0.72909691  0.15809072]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.2824153   0.60244305  0.72968748  0.157671  ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.276294    0.60433408  0.73068654  0.15664968]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.27372918  0.60548085  0.73072872  0.15652738]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.2740068   0.60541514  0.73085137  0.15572108]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.27435123  0.60497729  0.73133547  0.15453904]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.27635458  0.60398568  0.73134456  0.15480495]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.28112551  0.60233682  0.73064113  0.15595622]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.2835976   0.60089599  0.73105644  0.15508994]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.28442989  0.60040325  0.73170107  0.15241103]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.2848714   0.60063891  0.73165232  0.15088428]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.28399196  0.60171737  0.73169314  0.14802003]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.27918423  0.60416848  0.73252924  0.14295989]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.27819923  0.60624508  0.73161077  0.14077562]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.27667285  0.60783125  0.73101816  0.14002053]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.27425581  0.60965214  0.73065636  0.13874188]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.27080701  0.61269599  0.72943276  0.13854611]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.2680204   0.61535442  0.72819778  0.13867949]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.26270577  0.6184398   0.72742966  0.13915453]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.25662101  0.62156372  0.72658511  0.14099033]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.25190115  0.62363979  0.72618946  0.14236602]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.24495525  0.62591712  0.72639895  0.14341987]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.23414988  0.62945198  0.72648637  0.14553896]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.22702849  0.63166819  0.7268351   0.14547889]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.21763882  0.63426946  0.72782503  0.14354899]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.20996061  0.63616256  0.72899179  0.14065814]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.19657672  0.63943902  0.73076507  0.13585929]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.18644775  0.64187859  0.73200693  0.13188995]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.17518047  0.64406418  0.73377886  0.12673488]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.1601645   0.64699716  0.73568787  0.12043824]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.14445915  0.65089088  0.7367378   0.11265004]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.1305512   0.65480246  0.7370704   0.10448608]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.11681976  0.65923689  0.7368525   0.09385235]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.10564233  0.66337334  0.73606601  0.08356038]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.09673875  0.66757929  0.73478224  0.07123598]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.09035341  0.67097834  0.73365061  0.05814741]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.08625997  0.6730731   0.73299083  0.04750017]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.08371182  0.67479579  0.73230939  0.03695852]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.08084686  0.67580894  0.73198646  0.03069007]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.08141871  0.67673787  0.73116559  0.02817312]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.08089178  0.67754292  0.73046495  0.02851439]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.07992415  0.67841495  0.72962414  0.03184185]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.0785537   0.67930056  0.72880658  0.03494325]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.07704268  0.68040904  0.72772632  0.03901752]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.07467375  0.68138948  0.72691222  0.04160339]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.07160709  0.68323085  0.72541862  0.04284685]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.06779566  0.68484327  0.72428893  0.04241439]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.06134521  0.6875236   0.72244548  0.04025669]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.05616497  0.68959327  0.72103505  0.0376174 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.0491477   0.6922637   0.7191968   0.03333808]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.04359915  0.69358567  0.71843006  0.02993791]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.03836288  0.69456191  0.71785556  0.02820347]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.03617732  0.69475023  0.71779671  0.02794994]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.03598775  0.69409414  0.71839462  0.02910973]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.0373141   0.69230586  0.71991691  0.03224746]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.039444    0.69049001  0.72139837  0.03538514]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.04137257  0.68926463  0.72235558  0.03748327]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.04338449  0.68711338  0.72409474  0.04098523]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.0442037   0.6859521   0.72501308  0.04326414]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.04525156  0.68583297  0.72494563  0.0451583 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.04505174  0.68607503  0.72467803  0.04596893]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.04388429  0.68671628  0.72406519  0.04716486]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.04258634  0.68792748  0.72296695  0.04754971]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.04024808  0.6897503   0.72133297  0.04799338]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.03750844  0.6909413   0.72027945  0.04889528]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.03389977  0.69275456  0.71861904  0.0502852 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.03188801  0.69417153  0.71727589  0.05122824]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.02897189  0.69534824  0.71624145  0.05147459]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.02577294  0.69612923  0.71562252  0.05122757]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.02215033  0.69701457  0.71501771  0.04929217]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.01784004  0.69825441  0.71419266  0.04529198]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.01339148  0.69895966  0.71384314  0.04127987]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.00864429  0.69966517  0.71345862  0.03702332]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.00466057  0.70085901  0.71260568  0.03111392]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.00212929  0.70168133  0.71198561  0.02674442]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-1.02628774e-04  7.02283771e-01  7.11533809e-01  2.27405469e-02]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[0.00172491 0.70333659 0.710642   0.01739567]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[0.00195102 0.70417445 0.70989464 0.01356999]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[0.00199858 0.70508221 0.7090652  0.00903448]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[0.0018739  0.7057661  0.70842075 0.0055439 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[0.00120544 0.70650982 0.70769834 0.00234039]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[3.66600374e-05 7.07019096e-01 7.07194454e-01 2.55805590e-05]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.00150395  0.70699757  0.70721308 -0.00135294]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.00344804  0.70668524  0.70751652 -0.00211125]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.00472223  0.70640196  0.70779126 -0.00234614]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:627] Converted rotation matrix to quaternion: [[-0.006194    0.70581021  0.70836933 -0.0025458 ]].
[DEBUG] [add_camera_frustums() @ render_scene.py:665] [ALTERNATIVE] Adding camera frustum.
[DEBUG] [add_camera_frustums() @ render_scene.py:704] Added [332] camera frustums.
